{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入基本資料處理用函式庫\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# 引入 Pytorch 函式庫, 神經網路函式庫, Optimizer優化器 Loss function是要幫助我們判斷誤差值的，而Optimizer是要調整參數，來使Loss越小越好。\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料集分割器, 供多重驗證模型使用\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 引入單字,單詞分割器\n",
    "import tokenizers\n",
    "# 引入主要模型, RoBERTa (Robustly optimized BERT approach)\n",
    "from transformers import RobertaModel, RobertaConfig, logging\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此區塊主要用於調整所有用到的函式庫使用同一個種子碼，\n",
    "確保程式及訓練過程及結果可以重現。確保亂數的值固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    #調整 random, numpy, pytorch, python本體 的種子碼\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    # 若有 GPU 版本 Pytorch 可使用\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 設定種子碼為 30\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                               text  \\\n",
       "0           0   8  \"It can go both ways . We all doubt . It is wh...   \n",
       "1           1   8  \"It can go both ways . We all doubt . It is wh...   \n",
       "2           2   8  \"It can go both ways . We all doubt . It is wh...   \n",
       "3           3   9  \"once again , you seem to support the killing ...   \n",
       "4           4   9  \"once again , you seem to support the killing ...   \n",
       "\n",
       "  sentiment                                      selected_text  \n",
       "0     AGREE  \"It can go both ways . We all doubt . It is wh...  \n",
       "1     AGREE  \"can go both ways . We all doubt . It is what ...  \n",
       "2     AGREE  \"It can go both ways . We all doubt . It is wh...  \n",
       "3     AGREE    \"seem to support the killing of certain people\"  \n",
       "4     AGREE  \"you seem to support the killing of certain pe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76687</th>\n",
       "      <td>10001</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76688</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76689</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76690</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76691</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"might give you an idea about costs and concep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76692 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text sentiment  \\\n",
       "0          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "1          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "2          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "3          9  \"once again , you seem to support the killing ...     AGREE   \n",
       "4          9  \"once again , you seem to support the killing ...     AGREE   \n",
       "...      ...                                                ...       ...   \n",
       "76687  10001  \"And teen sex does n't , by the very nature of...  DISAGREE   \n",
       "76688  10002  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "76689  10002  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "76690  10003  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "76691  10003  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "\n",
       "                                           selected_text  \n",
       "0      \"It can go both ways . We all doubt . It is wh...  \n",
       "1      \"can go both ways . We all doubt . It is what ...  \n",
       "2      \"It can go both ways . We all doubt . It is wh...  \n",
       "3        \"seem to support the killing of certain people\"  \n",
       "4      \"you seem to support the killing of certain pe...  \n",
       "...                                                  ...  \n",
       "76687  \"And teen sex does n't , by the very nature of...  \n",
       "76688  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76689  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76690  \"Hi Smallax , welcome to the forum . I did a s...  \n",
       "76691  \"might give you an idea about costs and concep...  \n",
       "\n",
       "[76692 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['id','text','sentiment','selected_text']]\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContestDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, max_len=500):\n",
    "        self.df = df\n",
    "        self.max_lan = max_len\n",
    "        self.labeled = 'selected_text' in df\n",
    "        ''' \n",
    "        使用 byte level version of the BPE 為語詞分割器，以下定義: 切割字串編碼\n",
    "        - vocab_file :轉換為對應的編碼通常频率越高的byte索引越小\n",
    "        - merges_file : 輸入的所有tokens轉化为merges.txt中對應的byte\n",
    "        - lowercase : 是否將所有文字轉成小寫\n",
    "        - add_prefix_space : 是否於第一個文字前加入空白\n",
    "        '''\n",
    "        self.tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "            vocab = r\"C:\\python\\NLP_contest\\roberta-base\\vocab.json\",\n",
    "            merges = r\"C:\\python\\NLP_contest\\roberta-base\\merges.txt\",\n",
    "            lowercase = True,\n",
    "            add_prefix_space = True\n",
    "        )\n",
    "    # 定義針對此 class 呼叫 python 內建函式 len 的時候的回傳值\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def get_input_data(self, row):\n",
    "        '''\n",
    "        在該列的 text 前先加上一個空格，變小寫後根據空字元分割單詞，再以空格連接單詞\n",
    "        e.g 'Some User\\tInput' => ['some','user','input'] -> 'some user input'\n",
    "        '''\n",
    "        input_text = \" \"+ \" \".join(row.text.lower().split())\n",
    "        '''\n",
    "        藉 tokenizer 將 tweet 編碼成 BERT 中所需要的編號，每個編號對應著一個『字』\n",
    "        \n",
    "        '''\n",
    "        encoding = self.tokenizer.encode(input_text)\n",
    "        # 這裡也將列資料中的 sentiment 文字編碼\n",
    "        sentiment_id = self.tokenizer.encode(row.sentiment).ids\n",
    "        # encoding.ids 會回傳\n",
    "        ids = [0] + sentiment_id + [2, 2] + encoding.ids + [2]\n",
    "        # 確認 text 長度, 若不夠需補長\n",
    "        pad_len = self.max_lan - len(ids)\n",
    "        if pad_len > 0 :\n",
    "            ids += [1] * pad_len\n",
    "            offsets += [(0,0)] * pad_len\n",
    "        # 將 ids 轉為 pytorch 之 tensor\n",
    "        ids = torch.tensor(ids)\n",
    "        # 若 ids != 1 成立， masks 為 torch.tensor(1) , 否則 torch.tensor(0) #?\n",
    "        masks = torch.where(ids!=1, torch.tensor(1), torch.tensor(0))\n",
    "        # 將 offsets 轉為 pytorch 之 tensor\n",
    "        offsets = torch.tensor(offsets)\n",
    "\n",
    "        return ids, masks, input_text, offsets \n",
    "\n",
    "    '''\n",
    "    此資料集的目標是指出該列 Text 能夠判斷語氣的部份, \n",
    "    放置於 train 資料集的 selected_text 欄位\n",
    "    '''\n",
    "    def get_target_idx(self, row, input_text, offsets):\n",
    "        # 同上 text 處理方法\n",
    "        selected_text = \" \" +  \" \".join(row.selected_text.lower().split())\n",
    "\n",
    "        # 取出 selected_text 的長度\n",
    "        len_st = len(selected_text) - 1\n",
    "        # 建立 text 之 index 用 \n",
    "        idx0 = None\n",
    "        idx1 = None\n",
    "        for ind in (i for i, e in enumerate(input_text) if e == selected_text[1]):\n",
    "            # 若 \" \" + tweet[ind: ind+len_st] 的組合 和 selected_text 一樣\n",
    "            if \" \" + input_text[ind: ind+len_st] == selected_text:\n",
    "                # 設定 idx0 為起始點, idx1 為終止點\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                break\n",
    "        \n",
    "        # 先以 len(tweet) 個 [0] 初始化 char_targets\n",
    "        char_targets = [0] * len(input_text)\n",
    "        if idx0 != None and idx1 != None:\n",
    "        # 將 char_targets 對應 tweet 的 selected_text 位置 (idx0 ~ idx1 的範圍) 設為 1\n",
    "            for ct in range(idx0, idx1 + 1):\n",
    "                char_targets[ct] = 1\n",
    "\n",
    "        # 藉 offset 製造 target_idx 做訓練使用\n",
    "        target_idx = []\n",
    "        for j, (offset1, offset2) in enumerate(offsets):\n",
    "            # 若有發現 char_targets 中 範圍 offset1 至 offset2 的和大於 0 (代表有值)，\n",
    "            # 則將其 index 放入 target_idx\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                target_idx.append(j)\n",
    "\n",
    "        # 起始 idx 為 target_idx 中第一個，終止 idx 則為最後一個\n",
    "        start_idx = target_idx[0]\n",
    "        end_idx = target_idx[-1]\n",
    "        \n",
    "        return start_idx, end_idx\n",
    "\n",
    "\n",
    "    # 賦予此 Class 用 index 取值的能力， e.g. TweetDataset[1]\n",
    "    def __getitem__(self, index):\n",
    "        # 建立空的 dictionary\n",
    "        data = {}\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        # 使用 class 函式 get_input_data 根據 index row 取值且放入剛剛的 data dictionary\n",
    "        ids, masks, input_text, offsets = self.get_input_data(row)\n",
    "        data['ids'] = ids\n",
    "        data['masks'] = masks\n",
    "        # 由於 padding 會替不等長的句子們補0 ， 這時候利用masks就可以標註出非 0 的區域，也就是讓模型不被 padding 補的 0 影響判斷。\n",
    "        data['input_text'] = input_text\n",
    "        data['offsets'] = offsets\n",
    "\n",
    "        # 若 labeled 不為空集合則執行\n",
    "        if self.labeled:\n",
    "            # 使用 class 函式 get_target_idx, 額外針對目標取出 start_idx, end_idx \n",
    "            start_idx, end_idx = self.get_target_idx(row, input_text, offsets)\n",
    "            data['start_idx'] = start_idx\n",
    "            data['end_idx'] = end_idx\n",
    "            \n",
    "        # 回傳 data dictionary\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "傳入 dataframe, 分割後之 train 及 val 對應的 idx, 及預設為 4 的 batch_size\n",
    "回傳有 train 及 val DataLoader 的 dictionary\n",
    "'''\n",
    "def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n",
    "    # 藉 train_idx 及 val_idx 將 dataframe 分割成訓練及驗證 dataframe\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ContestDataSet(train_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,  # 打亂排序 \n",
    "        num_workers=2, # 以兩個 子行程處理\n",
    "        drop_last=True) # 當資料集 batch 無法均分時，捨棄最後一個不完整的 batch\n",
    "\n",
    "    # 要注意不要打亂排序避免 idx 錯亂\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ContestDataSet(val_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)\n",
    "    \n",
    "    # 用 dict 儲存兩個 Loader, 並且加上對應的 Key\n",
    "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    return dataloaders_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "傳入 dataframe, 及預設為 4 的 batch_size\n",
    "回傳 test 資料集使用的 Loader \n",
    "'''\n",
    "def get_test_loader(df, batch_size=16):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        ContestDataSet(df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, # 找出答案用, 所以不打亂順序\n",
    "        num_workers=2)  # 以兩個 子行程 處理    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model 基底繼承自 nn.Module神經網路模塊\n",
    "'''\n",
    "class ContestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContestModel, self).__init__()\n",
    "        # 以 pretrained (PyTorch 提供的預訓練模型) 的 config 初始化 RoBERTa configuration, 也將隱藏層的部分讀入\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            r\"C:\\python\\NLP_contest\\roberta-base\\config.json\",\n",
    "            output_hidden_states = True\n",
    "        )\n",
    "        # 讀入 pretrained 的 RobertaModel, 且以上面的 config 初始化\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            r\"C:\\python\\NLP_contest\\roberta-base\\pytorch_model.bin\",\n",
    "            config = config\n",
    "        )\n",
    "        # 設置一個 dropout 層工具，會隨機關閉 50% 的神經元避免過擬合\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # 建立全連接層工具，此種全連接層傳入 12 個節點(參考 config)，輸出兩個節點\n",
    "        self.fc = nn.Linear(config.hidden_size, 2)\n",
    "        # 以 標準差為 0.02 之 normal distribution 初始化 fc 之權重\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        # 以 均值為 0 之 normal distribution 初始化 fc 之 bias\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "\n",
    "    # 定義向前傳播時的行為，會輸入 指定的 ids 及 attention_mask\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 用 hs 保留輸入 input_ids, attention_mask 進 roberta 的隱藏層狀態\n",
    "        _, _, hs = self.roberta(input_ids, attention_mask)\n",
    "        # 沿著維度 0 號 疊起 hidden state:在LSTM 的網路結構中，直接根據當前input 資料，得到的輸出稱為\n",
    "        x = torch.stack([hs[-1], hs[-2], hs[-3], hs[-4]])\\\n",
    "        # 沿著維度 0 取均值\n",
    "        x = torch.mean(x, 0)\n",
    "        # 利用上面 init 的 dropout 層工具建立 dropout\n",
    "        x = self.dropout(x)\n",
    "        # 利用上面 init 的全連接層工具建立 fc\n",
    "        x = self.fc(x)\n",
    "        # 沿著最後一個維度，一個一組進行分割\n",
    "        start_logits, end_logits = x.split(1, dim=-1)\n",
    "        # 將兩個結果的最後一個維度去除\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        # 回傳 logits (語氣句子起始位置及結束位置分布機率)\n",
    "        return start_logits, end_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "建立 Loss Function 供訓練使用，\n",
    "基底是 CrossEntropy，但在此必須同時比對開頭位置及結束位置 ，CrossEntropy是在觀測預測的機率分佈與實際機率分布的誤差範圍\n",
    "所以程式將兩個的 CrossEntopyLoss 加起來計算。\n",
    "'''\n",
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    start_loss = ce_loss(start_logits, start_positions)\n",
    "    end_loss = ce_loss(end_logits, end_positions)    \n",
    "    total_loss = start_loss + end_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 藉 start_idx, end_idx, offsets 取出 test 中的 selected_text\n",
    "def get_selected_text(text, start_idx, end_idx, offsets):\n",
    "    selected_text = \"\"\n",
    "    for ix in range(start_idx, end_idx + 1):\n",
    "        # 先取出指定範圍\n",
    "        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n",
    "        # 確認是否需要加上空白做辨識\n",
    "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
    "            selected_text += \" \"\n",
    "    return selected_text\n",
    "\n",
    "# 建立 evaluation function - Jaccard index, 又稱Intersection over Union=一種測量在特定資料集中檢測相應物體準確度的一個標準\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    # 取聯集分之交集\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# 計算 jaccard_score\n",
    "def compute_jaccard_score(text, start_idx, end_idx, start_logits, end_logits, offsets):\n",
    "    # 取出 機率最大的位置\n",
    "    start_pred = np.argmax(start_logits)\n",
    "    end_pred = np.argmax(end_logits)\n",
    "    \n",
    "    # 此區取出預測區段文字，第一個條件判斷出有可能是整句文字的狀況\n",
    "    if start_pred > end_pred:\n",
    "        pred = text\n",
    "    else:\n",
    "        pred = get_selected_text(text, start_pred, end_pred, offsets)\n",
    "    \n",
    "    # 取出正確對應語氣的文字\n",
    "    true = get_selected_text(text, start_idx, end_idx, offsets)\n",
    "    \n",
    "    # 計算 jaccard_score\n",
    "    return jaccard(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "訓練模型使用， 引入 Model, 訓練及驗證 dataloader, loss function , optimizer, 訓練回數, 檔案名稱\n",
    "最後會儲存訓練後的模型。\n",
    "'''\n",
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename):\n",
    "    # 使用 GPU\n",
    "    model.cuda()\n",
    "\n",
    "    # 根據訓練回數，每回訓練進行...\n",
    "    for epoch in range(num_epochs):\n",
    "        # 判斷當前階段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            # 預設 loss 及 jaccard 為 0\n",
    "            epoch_loss = 0.0\n",
    "            epoch_jaccard = 0.0\n",
    "            \n",
    "            # 取出當前階段(train 或 val) 所使用的資料集，資料若是 torch tensor，在 GPU 訓練要轉成 GPU 使用的 Tesnor\n",
    "            for data in (dataloaders_dict[phase]):\n",
    "                ids = data['ids'].cuda()\n",
    "                masks = data['masks'].cuda()\n",
    "                tweet = data['tweet']\n",
    "                offsets = data['offsets'].numpy()\n",
    "                start_idx = data['start_idx'].cuda()\n",
    "                end_idx = data['end_idx'].cuda()\n",
    "                \n",
    "                # 初始化 optimizer\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    # 輸入 ids, masks 得到 model 輸出\n",
    "                    start_logits, end_logits = model(ids, masks)\n",
    "                    # 計算 loss\n",
    "                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n",
    "                    \n",
    "                    # 在訓練階段要反向傳播且讓 optimizer 進行梯度下降\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # 計算各批訓練 loss 之總和，loss.item() 目的在於將 loss 取出成 python float 形式\n",
    "                    epoch_loss += loss.item() * len(ids)\n",
    "                    \n",
    "                    # 以下步驟目的在於將 tensor 從 gpu 拿回 cpu 並且轉成 numpy array\n",
    "                    # .cpu() 用於將 tensor 放回 cpu\n",
    "                    # .detach() 用於阻斷反向傳播\n",
    "                    # .numpy() 將 tensor 轉為 numpy array\n",
    "                    start_idx = start_idx.cpu().detach().numpy()\n",
    "                    end_idx = end_idx.cpu().detach().numpy()\n",
    "                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n",
    "                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n",
    "                    \n",
    "                    # 計算本回的總 jaccard 分數總合\n",
    "                    for i in range(len(ids)):                        \n",
    "                        jaccard_score = compute_jaccard_score(\n",
    "                            tweet[i],\n",
    "                            start_idx[i],\n",
    "                            end_idx[i],\n",
    "                            start_logits[i], \n",
    "                            end_logits[i], \n",
    "                            offsets[i])\n",
    "                        epoch_jaccard += jaccard_score\n",
    "            \n",
    "            # 平均 loss 及 jaccard\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            # 印出當前 Loss 及 jaccard\n",
    "            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n",
    "                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n",
    "            \n",
    "    # 儲存模型\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練過程中數據將被輪3次\n",
    "num_epochs = 3\n",
    "# 每次批量訓練數量為 32\n",
    "batch_size = 8\n",
    "# 建立 KFold 多重驗證訓練器，分十種資料集分布且要打亂排序\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\python\\NLP_contest\\roberta-base\\pytorch_model.bin were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 將資料集以十種分布反覆進行訓練及驗證\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train.sentiment), start=1): \n",
    "    print(f'Fold: {fold}')\n",
    "    # 每種資料集分布都會建立一個新 model\n",
    "    model = ContestModel()\n",
    "    # 使用 AdamW 為 optimizer, 學習率 3e-5, betas 分別為 0.9 及 0.999\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
    "    # 呼叫 loss function\n",
    "    criterion = loss_fn\n",
    "    # 根據 train_idx 及 val_idx 的不同重新建立 data loader\n",
    "    dataloaders_dict = get_train_val_loaders(train, train_idx, val_idx, batch_size)\n",
    "\n",
    "    logging.set_verbosity_warning()\n",
    "    \n",
    "    # 呼叫模型進行訓練，儲存的 Model 名字為 (f'roberta_fold{fold}.pth')\n",
    "    train_model(\n",
    "        model, \n",
    "        dataloaders_dict,\n",
    "        criterion, \n",
    "        optimizer, \n",
    "        num_epochs,\n",
    "        f'roberta_fold{fold}.pth',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"it can go both ways . we all doubt . it is what you do with it that matters .\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \" \"+\" \".join(train['text'].iloc[0].lower().split())\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "            vocab = r\"C:\\python\\NLP_contest\\roberta-base\\vocab.json\",\n",
    "            merges = r\"C:\\python\\NLP_contest\\roberta-base\\merges.txt\",\n",
    "            lowercase = True,\n",
    "            add_prefix_space = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=21, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode(input_text)\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=1, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_id = tokenizer.encode(train.iloc[0].sentiment)\n",
    "sentiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2854]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_id.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2854,\n",
       " 2,\n",
       " 2,\n",
       " 22,\n",
       " 405,\n",
       " 64,\n",
       " 213,\n",
       " 258,\n",
       " 1319,\n",
       " 479,\n",
       " 52,\n",
       " 70,\n",
       " 2980,\n",
       " 479,\n",
       " 24,\n",
       " 16,\n",
       " 99,\n",
       " 47,\n",
       " 109,\n",
       " 19,\n",
       " 24,\n",
       " 14,\n",
       " 3510,\n",
       " 39058,\n",
       " 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [0] + sentiment_id.ids + [2, 2] + encoding.ids + [2]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 2),\n",
       " (2, 4),\n",
       " (4, 8),\n",
       " (8, 11),\n",
       " (11, 16),\n",
       " (16, 21),\n",
       " (21, 23),\n",
       " (23, 26),\n",
       " (26, 30),\n",
       " (30, 36),\n",
       " (36, 38),\n",
       " (38, 41),\n",
       " (41, 44),\n",
       " (44, 49),\n",
       " (49, 53),\n",
       " (53, 56),\n",
       " (56, 61),\n",
       " (61, 64),\n",
       " (64, 69),\n",
       " (69, 77),\n",
       " (77, 80),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = [(0, 0)]*4 + encoding.offsets + [(0, 0)]\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 79\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "selected_text = \" \" +  \" \".join(train['selected_text'].iloc[0].lower().split())\n",
    "\n",
    "        # 取出 selected_text 的長度\n",
    "len_st = len(selected_text) - 1\n",
    "        #建立 text 之 index 用 \n",
    "idx0 = None\n",
    "idx1 = None\n",
    "for ind in (i for i, e in enumerate(input_text) if e == selected_text[1]):\n",
    "        #print(input_text[ind: ind+len_st])\n",
    "        #     若 \" \" + tweet[ind: ind+len_st] 的組合 和 selected_text 一樣\n",
    "        #\n",
    "                # 設定 idx0 為起始點, idx1 為終止點\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                print(idx0, idx1)\n",
    "                break\n",
    "        \n",
    "        # 先以 len(tweet) 個 [0] 初始化 char_targets\n",
    "char_targets = [0] * len(input_text)\n",
    "\n",
    "if idx0 != None and idx1 != None:\n",
    "        # 將 char_targets 對應 tweet 的 selected_text 位置 (idx0 ~ idx1 的範圍) 設為 1\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "         char_targets[ct] = 1\n",
    "print(char_targets)\n",
    "# target_idx = []\n",
    "# for j, (offset1, offset2) in enumerate(offsets):\n",
    "#         #     若有發現 char_targets 中 範圍 offset1 至 offset2 的和大於 0 (代表有值)，\n",
    "#         #     則將其 index 放入 target_idx\n",
    "#     if sum(char_targets[offset1: offset2]) > 0:\n",
    "#                 target_idx.append(j)\n",
    "\n",
    "#         # 起始 idx 為 target_idx 中第一個，終止 idx 則為最後一個\n",
    "#     start_idx = target_idx[0]\n",
    "#     end_idx = target_idx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      " \"it can go both ways . we all doubt . it is what you do with it that matters .\"\n"
     ]
    }
   ],
   "source": [
    "selected_text = \" \" +  \" \".join(train['selected_text'].iloc[1].lower().split())\n",
    "input_text = \" \"+\" \".join(train['text'].iloc[1].lower().split())\n",
    "print(selected_text[1])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76687</th>\n",
       "      <td>76687</td>\n",
       "      <td>10001</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76688</th>\n",
       "      <td>76688</td>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76689</th>\n",
       "      <td>76689</td>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76690</th>\n",
       "      <td>76690</td>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76691</th>\n",
       "      <td>76691</td>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"might give you an idea about costs and concep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76692 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                               text  \\\n",
       "0               0      8  \"It can go both ways . We all doubt . It is wh...   \n",
       "1               1      8  \"It can go both ways . We all doubt . It is wh...   \n",
       "2               2      8  \"It can go both ways . We all doubt . It is wh...   \n",
       "3               3      9  \"once again , you seem to support the killing ...   \n",
       "4               4      9  \"once again , you seem to support the killing ...   \n",
       "...           ...    ...                                                ...   \n",
       "76687       76687  10001  \"And teen sex does n't , by the very nature of...   \n",
       "76688       76688  10002  \"Was n't sinjin crowing about his plans to tak...   \n",
       "76689       76689  10002  \"Was n't sinjin crowing about his plans to tak...   \n",
       "76690       76690  10003  \"Hi Smallax , welcome to the forum . I did a s...   \n",
       "76691       76691  10003  \"Hi Smallax , welcome to the forum . I did a s...   \n",
       "\n",
       "      sentiment                                      selected_text  \n",
       "0         AGREE  \"It can go both ways . We all doubt . It is wh...  \n",
       "1         AGREE  \"can go both ways . We all doubt . It is what ...  \n",
       "2         AGREE  \"It can go both ways . We all doubt . It is wh...  \n",
       "3         AGREE    \"seem to support the killing of certain people\"  \n",
       "4         AGREE  \"you seem to support the killing of certain pe...  \n",
       "...         ...                                                ...  \n",
       "76687  DISAGREE  \"And teen sex does n't , by the very nature of...  \n",
       "76688  DISAGREE  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76689  DISAGREE  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76690     AGREE  \"Hi Smallax , welcome to the forum . I did a s...  \n",
       "76691     AGREE  \"might give you an idea about costs and concep...  \n",
       "\n",
       "[76692 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(row):\n",
    "    return len(row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\NLP_contest\\RoBERTa_PyTorch.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/python/NLP_contest/RoBERTa_PyTorch.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(train)\n",
      "File \u001b[1;32mc:\\Users\\bill1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:756\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[39m# For data is scalar\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 756\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame constructor not properly called!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    758\u001b[0m     \u001b[39m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[39;00m\n\u001b[0;32m    759\u001b[0m     \u001b[39m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[39m# Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76687</th>\n",
       "      <td>10001</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76688</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76689</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76690</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76691</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"might give you an idea about costs and concep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75997 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text sentiment  \\\n",
       "0          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "1          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "2          8  \"It can go both ways . We all doubt . It is wh...     AGREE   \n",
       "3          9  \"once again , you seem to support the killing ...     AGREE   \n",
       "4          9  \"once again , you seem to support the killing ...     AGREE   \n",
       "...      ...                                                ...       ...   \n",
       "76687  10001  \"And teen sex does n't , by the very nature of...  DISAGREE   \n",
       "76688  10002  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "76689  10002  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "76690  10003  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "76691  10003  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "\n",
       "                                           selected_text  \n",
       "0      \"It can go both ways . We all doubt . It is wh...  \n",
       "1      \"can go both ways . We all doubt . It is what ...  \n",
       "2      \"It can go both ways . We all doubt . It is wh...  \n",
       "3        \"seem to support the killing of certain people\"  \n",
       "4      \"you seem to support the killing of certain pe...  \n",
       "...                                                  ...  \n",
       "76687  \"And teen sex does n't , by the very nature of...  \n",
       "76688  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76689  \"Was n't sinjin crowing about his plans to tak...  \n",
       "76690  \"Hi Smallax , welcome to the forum . I did a s...  \n",
       "76691  \"might give you an idea about costs and concep...  \n",
       "\n",
       "[75997 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  295,   296,   297,   298,   518,   519,   520,   521,   522,\n",
       "              523,\n",
       "            ...\n",
       "            74787, 74788, 74789, 74790, 74791, 74792, 75298, 75299, 75300,\n",
       "            75301],\n",
       "           dtype='int64', length=695)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = train['text'].apply(get_len)\n",
    "text_len[text_len>500].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(text_len[text_len>500].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f2e14debfada69c40213eed09438e301d98e71630f49e55fbed3e96c4754de7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
